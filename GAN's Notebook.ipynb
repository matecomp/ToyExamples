{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "image_summary = tf.summary.image\n",
    "scalar_summary = tf.summary.scalar\n",
    "histogram_summary = tf.summary.histogram\n",
    "merge_summary = tf.summary.merge\n",
    "SummaryWriter = tf.summary.FileWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions:\n",
    "1. Linear (Creates a fully connected layer)\n",
    "2. Conv2D (Creates a convolution layer)\n",
    "3. Deconv2D (Creates a deconvolution layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear args:\n",
    "    \n",
    "    input_: tensor to compose. Shape: [N, M]\n",
    "    output_size: number of output neurons\n",
    "    scope: name scope\n",
    "    stddev: standard deviation of gaussian distribution to use for random weight initialization\n",
    "    name: name scope\n",
    "    with_w: whether to also return parameter variables\n",
    "    \n",
    "__N : Number of samples.__\n",
    "\n",
    "__M : Number of features on input.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(input_, output_size, scope=None, stddev=0.02, bias_start=0.0, with_w=False):\n",
    "\n",
    "    shape = input_.get_shape().as_list()\n",
    "    \n",
    "    with tf.variable_scope(scope or \"Linear\"):\n",
    "        #If Matrix does not exits on scope, create a new variable\n",
    "        matrix = tf.get_variable(\"Matrix\", [shape[1], output_size], tf.float32,\n",
    "                                 tf.random_normal_initializer(stddev=stddev))\n",
    "        #If bias does not exits on scope, create a new variable\n",
    "        bias = tf.get_variable(\"bias\", [output_size],\n",
    "            initializer=tf.constant_initializer(bias_start))\n",
    "        #Return tensor with layer result and their weigths and bias\n",
    "        if with_w:\n",
    "            return tf.matmul(input_, matrix) + bias, matrix, bias\n",
    "        else:\n",
    "            return tf.matmul(input_, matrix) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D args:\n",
    "\n",
    "    input_: tensor to compose. Shape: [N, H, W, C]\n",
    "    output_dim: number of output features maps (activation)\n",
    "    k_h: kernel height\n",
    "    k_w: kernel width\n",
    "    d_h: horizontal stride\n",
    "    d_w: vertical stride\n",
    "    stddev: standard deviation of gaussian distribution to use for random weight initialization\n",
    "    name: name scope\n",
    "\n",
    "__N: Number of samples.__\n",
    "\n",
    "__H W C : Number of features on input (Height, Width, Channel).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input_, output_dim, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02, name=\"conv2d\"):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        #Depth of filter is equal to input depth and output_dim gives the depth of next layer\n",
    "        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
    "                            initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.nn.bias_add(conv, biases)\n",
    "\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconv2D args:\n",
    "\n",
    "    input_: tensor to compose. Shape: [N, H, W, C]\n",
    "    output_shape: output shape\n",
    "    k_h: kernel height\n",
    "    k_w: kernel width\n",
    "    d_h: horizontal stride\n",
    "    d_w: vertical stride\n",
    "    stddev: standard deviation of gaussian distribution to use for random weight initialization\n",
    "    name: name scope\n",
    "\n",
    "__N: Number of samples.__\n",
    "\n",
    "__H W C : Number of features on input (Height, Width, Channel).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv2d(input_, output_shape, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02, name=\"deconv2d\", with_w=False):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        # filter : [height, width, output_channels, in_channels]\n",
    "        w = tf.get_variable('w',\n",
    "                            [k_h, k_w, output_shape[-1],\n",
    "                            input_.get_shape()[-1]],\n",
    "                            initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "        deconv = tf.nn.conv2d_transpose(input_, w,\n",
    "                                        output_shape=output_shape,\n",
    "                                        strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
    "        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), output_shape)\n",
    "\n",
    "        if with_w:\n",
    "            return deconv, w, biases\n",
    "        else:\n",
    "            return deconv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function:\n",
    "### Leak Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization:\n",
    "    This class creates an op that composes the specified tensor with a batch normalization layer.\n",
    "### Args:\n",
    "    x: tensor to compose\n",
    "    train: set to True during training and False otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class batch_norm(object):\n",
    "\n",
    "    def __init__(self, epsilon=1e-5, momentum=0.9, name=\"batch_norm\"):\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            self.epsilon = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "\n",
    "    def __call__(self, x, train=True):\n",
    "        \n",
    "        return tf.contrib.layers.batch_norm(x,\n",
    "                                            decay=self.momentum,\n",
    "                                            updates_collections=None,\n",
    "                                            epsilon=self.epsilon,\n",
    "                                            scale=True,\n",
    "                                            is_training=train,\n",
    "                                            scope=self.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create model:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config model (Default):\n",
    "    output_size: (optional) The resolution in pixels of the images. [64]    \n",
    "    z_dim: (optional) Dimension of dim for Z. [100]\n",
    "    gf_dim: (optional) Dimension of gen filters in first conv layer. [64]\n",
    "    df_dim: (optional) Dimension of discrim filters in first conv layer. [64]\n",
    "    gfc_dim: (optional) Dimension of gen units for for fully connected layer. [1024]\n",
    "    dfc_dim: (optional) Dimension of discrim units for fully connected layer. [1024]\n",
    "    c_dim: (optional) Dimension of image color. For grayscale input, set to 1. [3]\n",
    "    is_training: whether this is a training graph\n",
    "    is_inference: whether this graph is created for inference/testing\n",
    "    x: input node. Shape: [N, H, W, C]\n",
    "    y: label. Shape: [N] for scalar labels, [N, H, W, C] otherwise. (Only defined if self._is_training is True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \n",
    "    def __init__(self, x):\n",
    "        \n",
    "        self.x = x\n",
    "        \n",
    "        image_size = 64\n",
    "        output_size = 64\n",
    "        c_dim = 3\n",
    "        z_dim = 100\n",
    "\n",
    "        self.dcgan_init(image_size=image_size, output_size=output_size, c_dim=c_dim, z_dim=z_dim)\n",
    "\n",
    "    def inference(self):\n",
    "        \"\"\"op to use for inference\"\"\"\n",
    "\n",
    "        # scale back to [0, 255] range\n",
    "        return tf.to_int32((self.G+127) * 128)\n",
    "\n",
    "    def loss(self):\n",
    "        \"\"\"\n",
    "        Loss function\n",
    "\n",
    "        Returns either an op or a list of dicts.\n",
    "        If the returned value is an op then DIGITS will optimize against this op\n",
    "        with respect to all trainable variables.\n",
    "        If the returned value is a list then DIGITS will optimize against each\n",
    "        loss in the list with respect to the specified variables.\n",
    "        \"\"\"\n",
    "\n",
    "        # here we are returning a list because we want to alternately optimize the\n",
    "        # discriminator and the generator.\n",
    "\n",
    "        losses = [\n",
    "            {'loss': self.d_loss, 'vars': self.d_vars},\n",
    "            {'loss': self.g_loss, 'vars': self.g_vars}\n",
    "        ]\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def dcgan_init(self,image_size,output_size,z_dim,c_dim,gf_dim=64,df_dim=64,gfc_dim=1024,dfc_dim=1024):\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.gf_dim = gf_dim\n",
    "        self.df_dim = df_dim\n",
    "\n",
    "        self.gfc_dim = gfc_dim\n",
    "        self.dfc_dim = dfc_dim\n",
    "\n",
    "        self.c_dim = c_dim\n",
    "\n",
    "        self.batch_size = tf.shape(self.x)[0]\n",
    "\n",
    "        self.soft_label_margin = 0.1\n",
    "        \n",
    "        # batch normalization : deals with poor initialization helps gradient flow\n",
    "        self.d_bn1 = batch_norm(name='d_bn1')\n",
    "        self.d_bn2 = batch_norm(name='d_bn2')\n",
    "        self.d_bn3 = batch_norm(name='d_bn3')\n",
    "\n",
    "        self.g_bn0 = batch_norm(name='g_bn0')\n",
    "        self.g_bn1 = batch_norm(name='g_bn1')\n",
    "        self.g_bn2 = batch_norm(name='g_bn2')\n",
    "        self.g_bn3 = batch_norm(name='g_bn3')\n",
    "        \n",
    "        self.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D network:\n",
    "    returns probability that image came from dataset -> D(x)\n",
    "### args:\n",
    "    - input - [N, 64, 64, 3]\n",
    "    - conv layer with 64 5x5 kernels and 2x2 stride - [N, 32, 32, 64]\n",
    "    - leaky relu - [N, 32, 32, 64]\n",
    "    - conv layer with 128 5x5 kernels and 2x2 stride - [N, 16, 16, 32]\n",
    "    - batch norm - [N, 16, 16, 32]\n",
    "    - leaky relu - [N, 16, 16, 32]\n",
    "    - conv layer with 256 5x5 kernels and 2x2 stride - [N, 8, 8, 256]\n",
    "    - batch norm - [N, 8, 8, 256]\n",
    "    - leaky relu - [N, 8, 8, 256]\n",
    "    - conv layer with 256 5x5 kernels and 2x2 stride - [N, 4, 4, 512]\n",
    "    - batch norm - [N, 4, 4, 512]\n",
    "    - leaky relu - [N, 4, 4, 512]\n",
    "    - flatten - [N, 8192]\n",
    "    - linear layer with 1 output neurons - [N, 1]\n",
    "    - sigmoid - [N,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #Make foward on a batch of images\n",
    "    def discriminator(self, image, y=None, reuse=False):\n",
    "\n",
    "        #Get N value\n",
    "        batch_size = image.get_shape().as_list()[0]\n",
    "\n",
    "        with tf.variable_scope(\"discriminator\") as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "\n",
    "            #0º layer is a conv layer 64 features maps\n",
    "            h0 = lrelu(conv2d(image, self.df_dim, name='d_h0_conv'))\n",
    "            \n",
    "            #1º layer is a conv layer 128 features maps\n",
    "            h1 = lrelu(self.d_bn1(conv2d(h0, self.df_dim * 2, name='d_h1_conv'), train=self.is_training))\n",
    "            \n",
    "            #2º layer is a conv layer 256 features maps\n",
    "            h2 = lrelu(self.d_bn2(conv2d(h1, self.df_dim * 4, name='d_h2_conv'), train=self.is_training))\n",
    "            \n",
    "            #3º layer is a conv layer 512 features maps\n",
    "            h3 = lrelu(self.d_bn3(conv2d(h2, self.df_dim * 8, name='d_h3_conv'), train=self.is_training))\n",
    "            \n",
    "            #Calculate size for flatten 2D layer (64/16)^2 = 4^2 = 16, 16*64*8 = 8192\n",
    "            h3_size = ((self.output_size // 16) ** 2) * self.df_dim * 8\n",
    "            \n",
    "            #4º layer is a flatten(512@4x4 to 8192 neurows) Fully connected a neuron that will be D(x) value\n",
    "            h4 = linear(tf.reshape(h3, [self.batch_size, h3_size]), 1, 'd_h4_lin')\n",
    "\n",
    "            return tf.nn.sigmoid(h4), h4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G foward:\n",
    "    returns generated image -> G(z)\n",
    "### args:\n",
    "    - input - [N, 100]\n",
    "    - linear layer with 8192 output neurons - [N, 8192]\n",
    "    - reshape - [N, 4, 4, 512]\n",
    "    - batch norm - [N, 4, 4, 512]\n",
    "    - relu - [N, 4, 4, 512]\n",
    "    - transpose convolution with 256 filters and stride 2 - [N, 8, 8, 256]\n",
    "    - batch norm - [N, 8, 8, 256]\n",
    "    - relu - [N, 8, 8, 256]\n",
    "    - transpose convolution with 128 filters and stride 2 - [N, 16, 16, 128]\n",
    "    - batch norm - [N, 16, 16, 128]\n",
    "    - relu - [N, 16, 16, 128]\n",
    "    - transpose convolution with 64 filters and stride 2 - [N, 32, 32, 64]\n",
    "    - batch norm - [N, 32, 32, 64]\n",
    "    - relu - [N, 32, 32, 64]\n",
    "    - transpose convolution with 3 filters and stride 2 - [N, 64, 64, 3]\n",
    "    - tanh - [N, 64, 64, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    #Make foward on a batch of z's\n",
    "    def generator(self, z, y=None):\n",
    "\n",
    "\n",
    "        with tf.variable_scope(\"generator\") as scope:\n",
    "\n",
    "            # 64 is the output size\n",
    "            s = self.output_size\n",
    "\n",
    "            # Layers sizes 32,16,8,4\n",
    "            s2, s4, s8, s16 = int(s // 2), int(s // 4), int(s // 8), int(s // 16)\n",
    "\n",
    "            #First layer is a fullyconnected layer\n",
    "            self.z_, self.h0_w, self.h0_b = linear(z, self.gf_dim * 8 * s16 * s16, 'g_h0_lin', with_w=True)\n",
    "\n",
    "            #Transform 1D layer in 2D layer because the next layer, this process is called feature maps\n",
    "            self.h0 = tf.reshape(self.z_, [-1, s16, s16, self.gf_dim * 8])\n",
    "            h0 = tf.nn.relu(self.g_bn0(self.h0, train=self.is_training))\n",
    "\n",
    "            #1º deconv(conv_transpose) layer [Samples, 8, 8, 256]\n",
    "            self.h1, self.h1_w, self.h1_b = deconv2d(h0,\n",
    "                [self.batch_size, s8, s8, self.gf_dim * 4], name='g_h1', with_w=True)\n",
    "            h1 = tf.nn.relu(self.g_bn1(self.h1, train=self.is_training))\n",
    "\n",
    "            #2º deconv(conv_transpose) layer [Samples, 16, 16, 128]\n",
    "            h2, self.h2_w, self.h2_b = deconv2d(h1,\n",
    "                [self.batch_size, s4, s4, self.gf_dim * 2], name='g_h2', with_w=True)\n",
    "            h2 = tf.nn.relu(self.g_bn2(h2, train=self.is_training))\n",
    "\n",
    "            #3º deconv(conv_transpose) layer [Samples, 32, 32, 34]\n",
    "            h3, self.h3_w, self.h3_b = deconv2d(h2,\n",
    "                [self.batch_size, s2, s2, self.gf_dim * 1], name='g_h3', with_w=True)\n",
    "            h3 = tf.nn.relu(self.g_bn3(h3, train=self.is_training))\n",
    "\n",
    "            #4º deconv(conv_transpose) layer [Samples, 64, 64, 3]\n",
    "            h4, self.h4_w, self.h4_b = deconv2d(h3,\n",
    "                [self.batch_size, s, s, self.c_dim], name='g_h4', with_w=True)\n",
    "\n",
    "            return tf.nn.tanh(h4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def build_model(self):\n",
    "\n",
    "        if not self.is_inference:\n",
    "            # create both the generator and the discriminator\n",
    "            # self.x is a batch of images - shape: [N, H, W, C]\n",
    "            # self.y is a vector of labels - shape: [N]\n",
    "\n",
    "            # sample z from a normal distribution\n",
    "            self.z = tf.random_normal(shape=[self.batch_size, self.z_dim], dtype=tf.float32, seed=None, name='z')\n",
    "\n",
    "            # scale input to [-1, +1] range\n",
    "            self.images = (tf.reshape(self.x,\n",
    "                                      shape=[self.batch_size,\n",
    "                                             self.image_size,\n",
    "                                             self.image_size,\n",
    "                                             self.c_dim],\n",
    "                                      name='x_reshaped') - 128)/ 127.\n",
    "\n",
    "            # create generator\n",
    "            self.G = self.generator(self.z)\n",
    "            # create an instance of the discriminator (real samples)\n",
    "            self.D, self.D_logits = self.discriminator(self.images, reuse=False)\n",
    "            # create another identical instance of the discriminator (fake samples)\n",
    "            # NOTE: we are re-using variables here to share weights between the two\n",
    "            # instances of the discriminator\n",
    "            self.D_, self.D_logits_ = self.discriminator(self.G, reuse=True)\n",
    "\n",
    "            # we are using the cross entropy loss for all these losses\n",
    "            # note the use of the soft label smoothing here to prevent D from getting overly confident\n",
    "            # on real samples\n",
    "            self.d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits,\n",
    "                                              tf.ones_like(self.D) - self.soft_label_margin,\n",
    "                                              name=\"loss_D_real\"))\n",
    "            self.d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits_,\n",
    "                                              tf.zeros_like(self.D_),\n",
    "                                              name=\"loss_D_fake\"))\n",
    "            self.d_loss = (self.d_loss_real + self.d_loss_fake) / 2.\n",
    "            # the typical GAN set-up is that of a minimax game where D is trying to minimize its own error and G is trying to maximize D's error\n",
    "            # however note how we are flipping G labels here: instead of maximizing D's error, we are minimizing D's error on the 'wrong' label\n",
    "            # this trick helps produce a stronger gradient\n",
    "            self.g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(self.D_logits_,\n",
    "                                              tf.ones_like(self.D_) + self.soft_label_margin,\n",
    "                                              name=\"loss_G\"))\n",
    "\n",
    "            # debug\n",
    "            self.summaries.append(image_summary(\"G\", self.G, max_outputs=3))\n",
    "            self.summaries.append(image_summary(\"X\", self.images, max_outputs=3))\n",
    "            self.summaries.append(histogram_summary(\"G_hist\", self.G))\n",
    "            self.summaries.append(histogram_summary(\"X_hist\", self.images))\n",
    "            self.summaries.append(scalar_summary(\"d_loss_real\", self.d_loss_real))\n",
    "            self.summaries.append(scalar_summary(\"d_loss_fake\", self.d_loss_fake))\n",
    "            self.summaries.append(scalar_summary(\"g_loss\", self.g_loss))\n",
    "            self.summaries.append(scalar_summary(\"d_loss\", self.d_loss))\n",
    "\n",
    "            # all trainable variables\n",
    "            t_vars = tf.trainable_variables()\n",
    "            # G variables\n",
    "            self.g_vars = [var for var in t_vars if 'g_' in var.name]\n",
    "            # D variables\n",
    "            self.d_vars = [var for var in t_vars if 'd_' in var.name]\n",
    "\n",
    "            # Extra hook for debug: log chi-square distance between G's output histogram and the dataset's histogram\n",
    "            value_range = [0.0, 1.0]\n",
    "            nbins = 100\n",
    "            hist_g = tf.histogram_fixed_width(self.G, value_range, nbins=nbins, dtype=tf.float32) / nbins\n",
    "            hist_images = tf.histogram_fixed_width(self.images, value_range, nbins=nbins, dtype=tf.float32) / nbins\n",
    "            chi_square = tf.reduce_mean(tf.div(tf.square(hist_g - hist_images), hist_g + hist_images + 1e-5))\n",
    "            self.summaries.append(scalar_summary(\"chi_square\", chi_square))\n",
    "        else:\n",
    "            # Create only the generator\n",
    "            self.x = tf.reshape(self.x, shape=[self.batch_size, self.z_dim])\n",
    "            self.z = self.x[:, :self.z_dim]\n",
    "            self.G = self.generator(self.z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset (Toy example)\n",
    "\n",
    "##     Generate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataDistribution(object):\n",
    "    def __init__(self):\n",
    "        self.mu = 4\n",
    "        self.sigma = 0.5\n",
    "\n",
    "    def sample(self, N):\n",
    "        samples = np.random.normal(self.mu, self.sigma, N)\n",
    "        samples.sort()\n",
    "        return samples\n",
    "\n",
    "class GeneratorDistribution(object):\n",
    "    def __init__(self, rang):\n",
    "        self.rang = rang\n",
    "\n",
    "    def sample(self, N):\n",
    "        return np.linspace(-self.rang, self.rang, N) + \\\n",
    "            np.random.random(N) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = DataDistribution()\n",
    "printer = GeneratorDistribution(100)\n",
    "x = printer.sample(100)\n",
    "y = data.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAFyCAYAAACk1ONFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZoCQJEnZDBCSJCnb/wdPPYEIyiZo7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7f1270050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y,50)\n",
    "plt.title('Normal distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Model instance has no attribute 'dcgan_init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-178b43c5a35e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-23e02565b123>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mz_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcgan_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Model instance has no attribute 'dcgan_init'"
     ]
    }
   ],
   "source": [
    "m = Model(y)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
